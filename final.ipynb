import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import cv2
import os
import random
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers, models
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint
import warnings
warnings.filterwarnings('ignore')

# Set random seeds for reproducibility
np.random.seed(42)
tf.random.set_seed(42)
random.seed(42)

print("TensorFlow version:", tf.__version__)
print("GPU Available:", tf.config.list_physical_devices('GPU'))

# Configuration
CONFIG = {
    'IMG_SIZE': (256, 256),
    'BATCH_SIZE': 32,
    'EPOCHS': 50,
    'LEARNING_RATE': 0.001,
    'VALIDATION_SPLIT': 0.2,
    'TEST_SPLIT': 0.1,
    'DATASET_PATH': 'CASIA2',  # Update this path to your CASIA 2.0 dataset location
    'MODEL_SAVE_PATH': 'forgery_detection_model.keras'
}

class HighPassFilters:
    """High-pass residual filters for forgery detection"""
    
    @staticmethod
    def srm_filter_1():
        """SRM (Spatial Rich Model) filter 1"""
        return np.array([[-1, 2, -1],
                        [2, -4, 2],
                        [-1, 2, -1]], dtype=np.float32)
    
    @staticmethod
    def srm_filter_2():
        """SRM filter 2"""
        return np.array([[-1, 2, -2, 2, -1],
                        [2, -6, 8, -6, 2],
                        [-2, 8, -12, 8, -2],
                        [2, -6, 8, -6, 2],
                        [-1, 2, -2, 2, -1]], dtype=np.float32)
    
    @staticmethod
    def laplacian_filter():
        """Laplacian high-pass filter"""
        return np.array([[0, -1, 0],
                        [-1, 4, -1],
                        [0, -1, 0]], dtype=np.float32)
    
    @staticmethod
    def sobel_x():
        """Sobel X filter"""
        return np.array([[-1, 0, 1],
                        [-2, 0, 2],
                        [-1, 0, 1]], dtype=np.float32)
    
    @staticmethod
    def sobel_y():
        """Sobel Y filter"""
        return np.array([[-1, -2, -1],
                        [0, 0, 0],
                        [1, 2, 1]], dtype=np.float32)

class ImageProcessor:
    """Image processing utilities with high-pass filtering"""
    
    def __init__(self, target_size=(256, 256)):
        self.target_size = target_size
        self.filters = HighPassFilters()
    
    def apply_high_pass_filter(self, image, filter_type='srm_1'):
        """Apply high-pass filter to image"""
        if len(image.shape) == 3:
            image = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)
        
        # Get the appropriate filter
        if filter_type == 'srm_1':
            kernel = self.filters.srm_filter_1()
        elif filter_type == 'srm_2':
            kernel = self.filters.srm_filter_2()
        elif filter_type == 'laplacian':
            kernel = self.filters.laplacian_filter()
        elif filter_type == 'sobel_x':
            kernel = self.filters.sobel_x()
        elif filter_type == 'sobel_y':
            kernel = self.filters.sobel_y()
        else:
            kernel = self.filters.srm_filter_1()
        
        # Apply filter
        filtered = cv2.filter2D(image.astype(np.float32), -1, kernel)
        
        # Normalize to [0, 255]
        filtered = np.clip(filtered + 128, 0, 255).astype(np.uint8)
        
        return filtered
    
    def preprocess_image(self, image_path, apply_filters=True):
        """Preprocess image with optional high-pass filtering"""
        # Read image
        image = cv2.imread(image_path)
        if image is None:
            return None
        
        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        image = cv2.resize(image, self.target_size)
        
        if apply_filters:
            # Apply multiple high-pass filters and stack them
            gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)
            
            # Apply different filters
            srm1 = self.apply_high_pass_filter(gray, 'srm_1')
            laplacian = self.apply_high_pass_filter(gray, 'laplacian')
            sobel_x = self.apply_high_pass_filter(gray, 'sobel_x')
            
            # Stack filtered images with original
            filtered_stack = np.stack([srm1, laplacian, sobel_x], axis=-1)
            
            # Normalize
            filtered_stack = filtered_stack.astype(np.float32) / 255.0
            
            return filtered_stack
        else:
            return image.astype(np.float32) / 255.0

class DatasetLoader:
    """CASIA 2.0 dataset loader with augmentation"""
    
    def __init__(self, dataset_path, img_processor):
        self.dataset_path = dataset_path
        self.img_processor = img_processor
        self.authentic_path = os.path.join(dataset_path, 'Au')
        self.tampered_path = os.path.join(dataset_path, 'Tp')
    
    def load_dataset(self, max_samples_per_class=None):
        """Load CASIA 2.0 dataset"""
        images = []
        labels = []
        
        print("Loading authentic images...")
        # Load authentic images
        if os.path.exists(self.authentic_path):
            auth_files = [f for f in os.listdir(self.authentic_path) 
                         if f.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp', '.tif'))]
            
            if max_samples_per_class:
                auth_files = auth_files[:max_samples_per_class]
            
            for i, filename in enumerate(auth_files):
                if i % 100 == 0:
                    print(f"Processed {i}/{len(auth_files)} authentic images")
                
                filepath = os.path.join(self.authentic_path, filename)
                processed_img = self.img_processor.preprocess_image(filepath)
                
                if processed_img is not None:
                    images.append(processed_img)
                    labels.append(0)  # 0 for authentic
        
        print("Loading tampered images...")
        # Load tampered images
        if os.path.exists(self.tampered_path):
            tamp_files = [f for f in os.listdir(self.tampered_path) 
                         if f.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp', '.tif'))]
            
            if max_samples_per_class:
                tamp_files = tamp_files[:max_samples_per_class]
            
            for i, filename in enumerate(tamp_files):
                if i % 100 == 0:
                    print(f"Processed {i}/{len(tamp_files)} tampered images")
                
                filepath = os.path.join(self.tampered_path, filename)
                processed_img = self.img_processor.preprocess_image(filepath)
                
                if processed_img is not None:
                    images.append(processed_img)
                    labels.append(1)  # 1 for tampered
        
        return np.array(images), np.array(labels)
    
    def create_data_generator(self):
        """Create data augmentation generator"""
        return ImageDataGenerator(
            rotation_range=10,
            width_shift_range=0.1,
            height_shift_range=0.1,
            shear_range=0.1,
            zoom_range=0.1,
            horizontal_flip=True,
            fill_mode='nearest',
            brightness_range=[0.8, 1.2],
            channel_shift_range=0.1
        )

class ForgeryDetectionCNN:
    """CNN model for image forgery detection"""
    
    def __init__(self, input_shape=(256, 256, 3)):
        self.input_shape = input_shape
        self.model = None
    
    def build_model(self):
        """Build CNN architecture optimized for forgery detection"""
        model = models.Sequential([
            # First convolutional block
            layers.Conv2D(32, (3, 3), activation='relu', input_shape=self.input_shape,
                         kernel_regularizer=keras.regularizers.l2(0.001)),
            layers.BatchNormalization(),
            layers.Conv2D(32, (3, 3), activation='relu',
                         kernel_regularizer=keras.regularizers.l2(0.001)),
            layers.MaxPooling2D((2, 2)),
            layers.Dropout(0.25),
            
            # Second convolutional block
            layers.Conv2D(64, (3, 3), activation='relu',
                         kernel_regularizer=keras.regularizers.l2(0.001)),
            layers.BatchNormalization(),
            layers.Conv2D(64, (3, 3), activation='relu',
                         kernel_regularizer=keras.regularizers.l2(0.001)),
            layers.MaxPooling2D((2, 2)),
            layers.Dropout(0.25),
            
            # Third convolutional block
            layers.Conv2D(128, (3, 3), activation='relu',
                         kernel_regularizer=keras.regularizers.l2(0.001)),
            layers.BatchNormalization(),
            layers.Conv2D(128, (3, 3), activation='relu',
                         kernel_regularizer=keras.regularizers.l2(0.001)),
            layers.MaxPooling2D((2, 2)),
            layers.Dropout(0.25),
            
            # Fourth convolutional block
            layers.Conv2D(256, (3, 3), activation='relu',
                         kernel_regularizer=keras.regularizers.l2(0.001)),
            layers.BatchNormalization(),
            layers.Conv2D(256, (3, 3), activation='relu',
                         kernel_regularizer=keras.regularizers.l2(0.001)),
            layers.MaxPooling2D((2, 2)),
            layers.Dropout(0.25),
            
            # Global Average Pooling instead of Flatten to reduce parameters
            layers.GlobalAveragePooling2D(),
            
            # Dense layers
            layers.Dense(512, activation='relu',
                        kernel_regularizer=keras.regularizers.l2(0.001)),
            layers.BatchNormalization(),
            layers.Dropout(0.5),
            
            layers.Dense(256, activation='relu',
                        kernel_regularizer=keras.regularizers.l2(0.001)),
            layers.BatchNormalization(),
            layers.Dropout(0.5),
            
            # Output layer
            layers.Dense(1, activation='sigmoid')
        ])
        
        self.model = model
        return model
    
    def compile_model(self, learning_rate=0.001):
        """Compile the model with optimizer and loss function"""
        optimizer = keras.optimizers.Adam(learning_rate=learning_rate)
        
        self.model.compile(
            optimizer=optimizer,
            loss='binary_crossentropy',
            metrics=['accuracy', 'precision', 'recall']
        )
        
        return self.model
    
    def get_callbacks(self, model_path):
        """Get training callbacks"""
        return [
            EarlyStopping(
                monitor='val_loss',
                patience=10,
                restore_best_weights=True,
                verbose=1
            ),
            ReduceLROnPlateau(
                monitor='val_loss',
                factor=0.5,
                patience=5,
                min_lr=1e-7,
                verbose=1
            ),
            ModelCheckpoint(
                filepath=model_path,
                monitor='val_accuracy',
                save_best_only=True,
                verbose=1
            )
        ]

class ModelEvaluator:
    """Model evaluation and visualization utilities"""
    
    def __init__(self, model):
        self.model = model
    
    def plot_training_history(self, history):
        """Plot training history"""
        fig, axes = plt.subplots(2, 2, figsize=(15, 10))
        
        # Accuracy
        axes[0, 0].plot(history.history['accuracy'], label='Training Accuracy')
        axes[0, 0].plot(history.history['val_accuracy'], label='Validation Accuracy')
        axes[0, 0].set_title('Model Accuracy')
        axes[0, 0].set_xlabel('Epoch')
        axes[0, 0].set_ylabel('Accuracy')
        axes[0, 0].legend()
        axes[0, 0].grid(True)
        
        # Loss
        axes[0, 1].plot(history.history['loss'], label='Training Loss')
        axes[0, 1].plot(history.history['val_loss'], label='Validation Loss')
        axes[0, 1].set_title('Model Loss')
        axes[0, 1].set_xlabel('Epoch')
        axes[0, 1].set_ylabel('Loss')
        axes[0, 1].legend()
        axes[0, 1].grid(True)
        
        # Precision
        axes[1, 0].plot(history.history['precision'], label='Training Precision')
        axes[1, 0].plot(history.history['val_precision'], label='Validation Precision')
        axes[1, 0].set_title('Model Precision')
        axes[1, 0].set_xlabel('Epoch')
        axes[1, 0].set_ylabel('Precision')
        axes[1, 0].legend()
        axes[1, 0].grid(True)
        
        # Recall
        axes[1, 1].plot(history.history['recall'], label='Training Recall')
        axes[1, 1].plot(history.history['val_recall'], label='Validation Recall')
        axes[1, 1].set_title('Model Recall')
        axes[1, 1].set_xlabel('Epoch')
        axes[1, 1].set_ylabel('Recall')
        axes[1, 1].legend()
        axes[1, 1].grid(True)
        
        plt.tight_layout()
        plt.show()
    
    def evaluate_model(self, X_test, y_test):
        """Comprehensive model evaluation"""
        # Make predictions
        y_pred_prob = self.model.predict(X_test)
        y_pred = (y_pred_prob > 0.5).astype(int)
        
        # Calculate metrics
        accuracy = accuracy_score(y_test, y_pred)
        
        print(f"Test Accuracy: {accuracy:.4f}")
        print("\nClassification Report:")
        print(classification_report(y_test, y_pred, 
                                  target_names=['Authentic', 'Tampered']))
        
        # Confusion Matrix
        cm = confusion_matrix(y_test, y_pred)
        
        plt.figure(figsize=(8, 6))
        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', 
                   xticklabels=['Authentic', 'Tampered'],
                   yticklabels=['Authentic', 'Tampered'])
        plt.title('Confusion Matrix')
        plt.xlabel('Predicted')
        plt.ylabel('Actual')
        plt.show()
        
        return accuracy, y_pred_prob
    
    def visualize_predictions(self, X_test, y_test, y_pred_prob, num_samples=8):
        """Visualize model predictions on test samples"""
        indices = np.random.choice(len(X_test), num_samples, replace=False)
        
        fig, axes = plt.subplots(2, 4, figsize=(16, 8))
        axes = axes.ravel()
        
        for i, idx in enumerate(indices):
            # Display original image (if 3 channels) or filtered image
            if X_test[idx].shape[-1] == 3:
                if X_test[idx].max() <= 1:
                    img_display = X_test[idx]
                else:
                    img_display = X_test[idx] / 255.0
            else:
                img_display = X_test[idx][:, :, 0]  # Show first channel
            
            axes[i].imshow(img_display, cmap='gray' if len(img_display.shape) == 2 else None)
            
            true_label = "Tampered" if y_test[idx] == 1 else "Authentic"
            pred_prob = y_pred_prob[idx][0]
            pred_label = "Tampered" if pred_prob > 0.5 else "Authentic"
            
            axes[i].set_title(f'True: {true_label}\nPred: {pred_label} ({pred_prob:.3f})')
            axes[i].axis('off')
        
        plt.tight_layout()
        plt.show()

# Main execution pipeline
def main():
    """Main execution pipeline"""
    
    print("=== CNN-Based Image Splicing Forgery Detection ===\n")
    
    # Initialize components
    img_processor = ImageProcessor(target_size=CONFIG['IMG_SIZE'])
    dataset_loader = DatasetLoader(CONFIG['DATASET_PATH'], img_processor)
    
    # Load dataset (use smaller sample for demonstration)
    print("Loading dataset...")
    X, y = dataset_loader.load_dataset(max_samples_per_class=1000)  # Limit for demo
    
    print(f"Dataset loaded: {len(X)} images")
    print(f"Authentic images: {np.sum(y == 0)}")
    print(f"Tampered images: {np.sum(y == 1)}")
    print(f"Image shape: {X[0].shape}")
    
    # Split dataset
    X_temp, X_test, y_temp, y_test = train_test_split(
        X, y, test_size=CONFIG['TEST_SPLIT'], random_state=42, stratify=y
    )
    
    X_train, X_val, y_train, y_val = train_test_split(
        X_temp, y_temp, test_size=CONFIG['VALIDATION_SPLIT']/(1-CONFIG['TEST_SPLIT']), 
        random_state=42, stratify=y_temp
    )
    
    print(f"\nTraining set: {len(X_train)} images")
    print(f"Validation set: {len(X_val)} images")
    print(f"Test set: {len(X_test)} images")
    
    # Build and compile model
    print("\nBuilding CNN model...")
    cnn_model = ForgeryDetectionCNN(input_shape=X[0].shape)
    model = cnn_model.build_model()
    model = cnn_model.compile_model(learning_rate=CONFIG['LEARNING_RATE'])
    
    print(model.summary())
    
    # Data augmentation
    datagen = dataset_loader.create_data_generator()
    
    # Train model
    print("\nStarting training...")
    callbacks = cnn_model.get_callbacks(CONFIG['MODEL_SAVE_PATH'])
    
    history = model.fit(
        datagen.flow(X_train, y_train, batch_size=CONFIG['BATCH_SIZE']),
        epochs=CONFIG['EPOCHS'],
        validation_data=(X_val, y_val),
        callbacks=callbacks,
        verbose=1
    )
    
    # Evaluate model
    print("\nEvaluating model...")
    evaluator = ModelEvaluator(model)
    
    # Plot training history
    evaluator.plot_training_history(history)
    
    # Evaluate on test set
    accuracy, predictions = evaluator.evaluate_model(X_test, y_test)
    
    # Visualize predictions
    evaluator.visualize_predictions(X_test, y_test, predictions)
    
    print(f"\nModel saved to: {CONFIG['MODEL_SAVE_PATH']}")
    print("Training completed successfully!")

# Function to test on individual images
def test_single_image(model_path, image_path):
    """Test trained model on a single image"""
    
    # Load trained model
    model = keras.models.load_model(model_path)
    
    # Process image
    img_processor = ImageProcessor()
    processed_img = img_processor.preprocess_image(image_path)
    
    if processed_img is None:
        print("Error loading image")
        return
    
    # Make prediction
    prediction = model.predict(np.expand_dims(processed_img, axis=0))[0][0]
    
    # Display result
    plt.figure(figsize=(10, 5))
    
    plt.subplot(1, 2, 1)
    if processed_img.shape[-1] == 3:
        plt.imshow(processed_img)
    else:
        plt.imshow(processed_img[:, :, 0], cmap='gray')
    plt.title('Processed Image')
    plt.axis('off')
    
    plt.subplot(1, 2, 2)
    colors = ['green' if prediction < 0.5 else 'red']
    labels = ['Authentic' if prediction < 0.5 else 'Tampered']
    plt.bar(labels, [prediction if prediction > 0.5 else 1-prediction], color=colors)
    plt.title(f'Prediction: {labels[0]} ({prediction:.3f})')
    plt.ylim(0, 1)
    
    plt.tight_layout()
    plt.show()
    
    return prediction

# Run the main pipeline
if __name__ == "__main__":
    # Update CONFIG['DATASET_PATH'] to point to your CASIA 2.0 dataset location
    # The dataset should have the following structure:
    # CASIA2/
    # ├── Au/          (Authentic images)
    # └── Tp/          (Tampered images)
    
    # Uncomment the line below to run the full pipeline
    main()
    
    # Example of testing a single image after training
    # test_single_image('forgery_detection_model.keras', 'path_to_test_image.jpg')
    
    print("Setup complete! Update the dataset path and run main() to start training.")
